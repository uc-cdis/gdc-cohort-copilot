# GDC Cohort Copilot

**GDC Cohort Copilot** is an AI copilot tool to assist in the curation of cohorts from the NCI GDC using natural language. We share GDC Cohort Copilot as a containerized web app backed by a locally served LLM. The container is available at: [https://quay.io/repository/cdis/gdc-cohort-copilot](https://quay.io/repository/cdis/gdc-cohort-copilot).

We recommend using `docker` to run the GDC Cohort Copilot container. Run the command below before opening http://localhost:8000 in a web browser:
```bash
docker run -it --rm -p 8000:8000 --runtime nvidia --gpus all quay.io/cdis/gdc-cohort-copilot:latest
```

* Our image requires GPU acceleration to run:
    * Install [nvidia-container-toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) if not already installed.
    * Please refer to the `docker run` documentation on [accessing GPUs](https://docs.docker.com/reference/cli/docker/container/run/#gpus) for additional details.
* Any additional arguments after the image name are passed to `vllm serve`. The only limitation is that the vLLM model and port arguments should not be overridden.
* The app runs on port `8000` within the container, however if port `8000` is occupied on the host, you can remap it. Refer to the `docker run` documentation on [host/container port mapping](https://docs.docker.com/reference/cli/docker/container/run/#publish) for details.
* If serving remotely, you will need to ssh tunnel from your local to the remote host before being able to open the app in your web browser:
    ```bash
    ssh -NL 8000:localhost:8000 <user>@<remote>
    ```

# Method

![overview figure](figs/GDC%20Cohort%20Copilot%20Overview.png)

Overview of GDC Cohort Copilot implementation and user workflow:
<ol type="A">
  <li>Implementation fo GDC Cohort Copilot involves training the Cohort-LLM to translate from a natural language query of a cohort to the cohort filter JSON. The cohort JSONs are derived from datasests of real user-made cohorts or synthetically generated cohorts. The paired natural language queries are generated by a frozen LLM using the cohort JSONs. The final trained Cohort-LLM model is packaged with a vLLM inference server and FastAPI web app inside a docker container.</li>
  <li>The workflow of a new GDC user with the GDC Cohort Copilot involves:</li>
  <ol>
    <li>Inputting a natural language description of a desired cohort</li>
    <li>An automatic API request to the web app server with the query</li>
    <li>Generation of the corresponding cohort filter by Cohort-LLM</li>
    <li>Iterative and interactive refinement of the cohort by the user</li>
    <li>Outputting the curated cohort to the NCI GDC</li>
  </ol>
</ol>

## Cohort-LLM

In addition to the containerized application, we also include our source code for developing and evaluating **Cohort-LLM**, the generative language model powering the GDC Cohort Copilot. We share all experimental variants of Cohort-LLM on huggingface: [https://huggingface.co/uc-ctds](https://huggingface.co/uc-ctds).

In order, the steps for our experiments are:
1. Setup and activate development environment
    ```
    conda env create -f env.yaml
    conda activate cohort
    ```
1. [Data Preprocessing](./data-preprocessing)
1. [Synthetic Data Generation](./data-generation)
1. [Model Training and Inference](./cohort-llm)
1. [OpenAI Comparison](./openai-prompting)
1. [Evaluation](./evaluation)
1. [Containerization](./docker)

# Citation

```
@article{song2025gdc,
  title={GDC Cohort Copilot: An AI Copilot for Curating Cohorts from the Genomic Data Commons},
  author={Song, Steven and Subramanyam, Anirudh and Zhang, Zhenyu and Venkat, Aarti and Grossman, Robert L},
  journal={TODO},
  year={2025}
}
```
